mod1 <- train(x = as.matrix(df.train[,2:34]),
y = as.factor(df.train$rich),
method = "lda",
trControl = cvCtrl)
## remember getTrainPerf?
getTrainPerf(mod1) #not great! this is the average cross-validated performance
## Once you have the framework set up, changing algorithm is trivial
#   Here is an SVM
set.seed(1)
mod2 <- train(x= as.matrix(df.train[,2:34]),
y = as.factor(df.train$rich),
method = "svmLinear2",
trControl = cvCtrl)
getTrainPerf(mod2) # SVM did about the same as LDA
##### advanced - see all the available algorithms (over 100) ####
## This is a little obscure, but here we can check what models are available
#    if we wanted to do classification/or dual use
t <- getModelInfo()
m <- list();
for (i in names(t)){
if (t[[i]]$type != "Regression"){
m <- c(m, t[i])
}
}
names(m)[1:5]
## The caret model structure can be used to predict new outcomes
#     there is a function called predict that you use to make predictions with a model
mod2.out <- predict(mod2, newdata = df.test[,2:34])
confusionMatrix(data = mod2.out, reference = df.test$rich)
svmGrid <- expand.grid(.sigma = c(1, 0.1, 0.05),
.C = c(1.0, 0.5, 0.1, 0.05))
# Tying it all together
set.seed(123)
mod6 <- train(x = as.matrix(df.train[,2:34]),
y = as.factor(df.train$rich),
method = "svmRadial",
tuneGrid = svmGrid,
trControl = cvCtrl)
getTrainPerf(mod6)
print(mod6) # Inspect the model summary
# test the fancier model on the left out participants
mod6.out <- predict(mod6, newdata = df.test[,2:34])
# see how well it did
confusionMatrix(data = mod6.out, reference = df.test$rich)
library("caret")
library("dplyr")
set.seed(1)
## Generate data
set.seed(1)
df <- twoClassSim(n = 100,
linearVars = 5,
noiseVars = 10,
corrVars = 15,
corrValue = 0.8)
df <- df %>%
mutate(rich = factor(Class, labels = c("yes", "no") )) %>% # convert class variable to yes/no
select(rich, Linear1:Corr15, -Class) # remove the Class column from the data frame
# Name the variables
names(df)[2:6]   <- c("age", "female", "income", "race", "employment")
names(df)[7:9]   <- c("diabetes", "hypertension", "cancer")
names(df)[10:19] <- c("red", "orange", "yellow", "green", "blue",
"indigo", "violet","gold", "silver", "bronze")
names(df)[20:ncol(df)] <- letters[1:15]
df$female <- ifelse(df$female < median(df$female), "0", "1")
df$income <- -1 * df$income
write.csv(df[1:50, ],
file.path(getwd(), "input/class_training_data.csv"),
row.names = FALSE)
write.csv(df[1:50, ],
file.path(getwd(), "input/class_training_data.csv"),
row.names = FALSE
)
write.csv(df[51:100, ],
file.path(getwd(), "input/class_testing_data.csv"),
row.names = FALSE
)
wd <- setwd("/Users/adamchekroud/Documents/PhD/PhD_Core/Teaching/yale_ml_workshop")
library("ggplot2")
library("caret")
library("dplyr")
library("e1071")
# Read data
df.train      <- read.csv(file.path(wd, "input/class_training_data.csv"),
as.is=TRUE
)
df.train$rich <- as.factor(df.train$rich)
## View top of data frame in console
head(df.train[,1:7])
## Any missing data?
complete.cases(df.train) %>% table()
## Do higher income ppl identify as rich?
ggplot(data = df.train) +
geom_boxplot(aes(y = income, x = rich)) +
coord_flip()
## Typical approach: logistic regression
lr1 <- glm(rich ~ ., family = "binomial", data = df.train)
summary(lr1)
pca1  <- prcomp(df.train[,-1])
df.pc <- pca1$x %>% as.data.frame()
## Take top 10 components (guess)
df.pc <- df.pc[,1:11]
## Put rich (outcome) back in
df.pc$rich <- df.train$rich
## Try the logistic regression again?
pc.LR <- glm(rich ~ ., family = "binomial", data = df.pc)
summary(pc.LR)
## Extract the predictions
pc.LR.out <- pc.LR$fitted.values
## Threshold the predictions, since we have a binary outcome
pc.LR.out <- ifelse(pc.LR.out < 0.5, "no", "yes")
## Confusion Matrices are really easy! Use this function!
confusionMatrix(data = pc.LR.out,
reference = df.train$rich
)
# correlate each variable with the outcome
correlations <- sapply(names(df.train)[-1],
function(i) cor(as.numeric(df.train[,i]), as.numeric(df.train$rich))
)
summary(correlations)
fs1 <- names(correlations)[(correlations > 0.2) | (correlations < -0.2)]
df.fs1 <- dplyr::select(df.train, one_of(c("rich", fs1)))
fs1.lr <- glm(rich ~ ., family = "binomial", data = df.fs1)
confusionMatrix(data = ifelse(fs1.lr$fitted.values < 0.5, "no", "yes"),
reference = df.fs1$rich
)
# Read in the second half of the class data
df.test      <- read.csv(file.path(wd, "class_testing_data.csv"),
as.is=TRUE
)
df.test$rich <- as.factor(df.test$rich)
# Apply the learned PCA matrix to the test data
df.test.PC <- predict(pca1,
newdata = df.test[ , -1]
)[,1:11] %>%
as.data.frame
# Predict `rich` using the PC logistic regression
test.PC.out <- predict(pc.LR, newdata = df.test.PC, type = "response")
# Threshold the predictions
test.PC.out <- ifelse(test.PC.out < 0.5, "no", "yes")
# Create a Confusion Matrix
confusionMatrix(data = test.PC.out, reference = df.test$rich)
# Make predictions only using predictors that had good correlations in training data
fs1.test <- predict(fs1.lr,
newdata = df.test[fs1],
type = "response"
)
# Threshold the predictions
test.fs1.out <- ifelse(fs1.test < 0.5, "no", "yes")
# how did it do?
confusionMatrix(data = test.fs1.out,
reference = df.test$rich
)
cvCtrl <- trainControl(method = "cv",
number = 10,
classProbs = TRUE
)   # see help for other CV
# LDA learner
set.seed(1)
mod1 <- train(x = as.matrix(df.train[,-1]),
y = as.factor(df.train$rich),
method = "lda",
trControl = cvCtrl
)
## remember getTrainPerf?
getTrainPerf(mod1)
set.seed(1)
mod2 <- train(x = as.matrix(df.train[, -1]),
y = as.factor(df.train$rich),
method = "svmLinear2",
trControl = cvCtrl
)
getTrainPerf(mod2)
set.seed(1)
mod3 <- train(x = as.matrix(df.train[, -1]),
y = as.factor(df.train$rich),
method = "knn",
trControl = cvCtrl
)
getTrainPerf(mod3) # kNN actually did much better than other methods
set.seed(1)
mod4 <- train(x = as.matrix(df.train[, -1]),
y = as.factor(df.train$rich),
method = "rf",
trControl = cvCtrl
)
getTrainPerf(mod4)
set.seed(1)
mod5 <- train(x = as.matrix(df.train[, -1]),
y = as.factor(df.train$rich),
method = "nnet",
trControl = cvCtrl
)
getTrainPerf(mod5)
set.seed(1)
mod6 <- train(x = as.matrix(df.train[, -1]),
y = as.factor(df.train$rich),
method = "bayesglm",
trControl = cvCtrl
)
getTrainPerf(mod6)
mod2$method
mod2.out <- predict(mod2, newdata = df.test[ -1])
confusionMatrix(data = mod2.out, reference = df.test$rich)
mod3$method
mod3.out <- predict(mod3, newdata = df.test[ -1])
confusionMatrix(data = mod3.out, reference = df.test$rich)
mod4$method
mod4.out <- predict(mod4, newdata = df.test[ -1])
confusionMatrix(data = mod4.out, reference = df.test$rich)
mod5$method
mod5.out <- predict(mod5, newdata = df.test[ -1])
confusionMatrix(data = mod5.out, reference = df.test$rich)
mod6$method
mod6.out <- predict(mod6, newdata = df.test[ -1])
confusionMatrix(data = mod6.out, reference = df.test$rich)
areyoupatient <- FALSE
if (areyoupatient) {
modLOO <- train(x= as.matrix(df.train[, -1]),
y = as.factor(df.train$rich),
method = "svmLinear",
trControl = trainControl(method="LOOCV")
)
# it is typically very slow. don't run
# it. there are as many folds /
# re-estimations as there are
# observations
}
set.seed(123)
modDef <- train(x = as.matrix(df.train[, -1]),
y = as.factor(df.train$rich),
method = "rf",
trControl = cvCtrl
)
print(modDef)
getTrainPerf(modDef)
set.seed(123)
modNoGrid <- train(x = as.matrix(df.train[, -1]),
y = as.factor(df.train$rich),
method = "rf",
tuneLength = 10,
trControl = cvCtrl
)
print(modNoGrid)
getTrainPerf(modNoGrid)
rfGrid <- expand.grid(mtry = seq(3, 21, by = 3))
set.seed(123)
modGrid <- train(x = as.matrix(df.train[, -1]),
y = as.factor(df.train$rich),
method = "rf",
tuneGrid = rfGrid,
trControl = cvCtrl
)
print(modGrid)
getTrainPerf(modGrid)
rfGrid2 <- expand.grid(mtry = seq(3, 10, by = 1))
set.seed(123)
modGrid2 <- train(x = as.matrix(df.train[, -1]),
y = as.factor(df.train$rich),
method = "rf",
tuneGrid = rfGrid2,
trControl = cvCtrl
)
print(modGrid2)
getTrainPerf(modGrid2)
print(modGrid)
getTrainPerf(modGrid)
modDef$bestTune
modDef.out <- predict(modDef, newdata = df.test[ -1])
confusionMatrix(data = modDef.out, reference = df.test$rich)
modNoGrid$bestTune
modNoGrid.out <- predict(modNoGrid, newdata = df.test[ -1])
confusionMatrix(data = modNoGrid.out, reference = df.test$rich)
modGrid$bestTune
modGrid.out <- predict(modGrid, newdata = df.test[ -1])
confusionMatrix(data = modGrid.out, reference = df.test$rich)
modGrid2$bestTune
modGrid2.out <- predict(modGrid2, newdata = df.test[ -1])
confusionMatrix(data = modGrid2.out, reference = df.test$rich)
wd <- setwd("/Users/adamchekroud/Documents/PhD/PhD_Core/Teaching/yale_ml_workshop")
library("ggplot2")
library("caret")
library("dplyr")
library("e1071")
# Read data
df.train      <- read.csv(file.path(wd, "input/class_training_data.csv"),
as.is=TRUE
)
df.train$rich <- as.factor(df.train$rich)
## View top of data frame in console
head(df.train[,1:7])
clear()
clc()
wd <- setwd("/Users/adamchekroud/Documents/PhD/PhD_Core/Teaching/yale_ml_workshop")
setwd(wd)
library("ggplot2")
library("caret")
library("dplyr")
library("e1071")
# Read data
df.train      <- read.csv(file.path(wd, "input/class_training_data.csv"),
as.is=TRUE
)
df.train$rich <- as.factor(df.train$rich)
## View top of data frame in console
head(df.train[,1:7])
## Any missing data?
complete.cases(df.train) %>% table()
## Do higher income ppl identify as rich?
ggplot(data = df.train) +
geom_boxplot(aes(y = income, x = rich)) +
coord_flip()
## Typical approach: logistic regression
lr1 <- glm(rich ~ ., family = "binomial", data = df.train)
pca1  <- prcomp(df.train[,-1])
df.pc <- pca1$x %>% as.data.frame()
## Take top 10 components (guess)
df.pc <- df.pc[,1:11]
## Put rich (outcome) back in
df.pc$rich <- df.train$rich
## Try the logistic regression again?
pc.LR <- glm(rich ~ ., family = "binomial", data = df.pc)
summary(pc.LR)
## Extract the predictions
pc.LR.out <- pc.LR$fitted.values
## Threshold the predictions, since we have a binary outcome
pc.LR.out <- ifelse(pc.LR.out < 0.5, "no", "yes")
## Confusion Matrices are really easy! Use this function!
confusionMatrix(data = pc.LR.out,
reference = df.train$rich
)
# correlate each variable with the outcome
correlations <- sapply(names(df.train)[-1],
function(i) cor(as.numeric(df.train[,i]), as.numeric(df.train$rich))
)
summary(correlations)
fs1 <- names(correlations)[(correlations > 0.2) | (correlations < -0.2)]
df.fs1 <- dplyr::select(df.train, one_of(c("rich", fs1)))
fs1.lr <- glm(rich ~ ., family = "binomial", data = df.fs1)
confusionMatrix(data = ifelse(fs1.lr$fitted.values < 0.5, "no", "yes"),
reference = df.fs1$rich
)
# Read in the second half of the class data
df.test      <- read.csv(file.path(wd, "class_testing_data.csv"),
as.is=TRUE
)
# Read in the second half of the class data
df.test      <- read.csv(file.path(wd, "input/class_testing_data.csv"),
as.is=TRUE
)
# Read in the second half of the class data
df.test      <- read.csv(file.path(wd, "input/class_testing_data.csv"),
as.is=TRUE
)
df.test$rich <- as.factor(df.test$rich)
# Apply the learned PCA matrix to the test data
df.test.PC <- predict(pca1,
newdata = df.test[ , -1]
)[,1:11] %>%
as.data.frame
# Predict `rich` using the PC logistic regression
test.PC.out <- predict(pc.LR, newdata = df.test.PC, type = "response")
# Threshold the predictions
test.PC.out <- ifelse(test.PC.out < 0.5, "no", "yes")
# Create a Confusion Matrix
confusionMatrix(data = test.PC.out, reference = df.test$rich)
# Make predictions only using predictors that had good correlations in training data
fs1.test <- predict(fs1.lr,
newdata = df.test[fs1],
type = "response"
)
# Threshold the predictions
test.fs1.out <- ifelse(fs1.test < 0.5, "no", "yes")
# how did it do?
confusionMatrix(data = test.fs1.out,
reference = df.test$rich
)
cvCtrl <- trainControl(method = "cv",
number = 10,
classProbs = TRUE
)   # see help for other CV
# LDA learner
set.seed(1)
mod1 <- train(x = as.matrix(df.train[,-1]),
y = as.factor(df.train$rich),
method = "lda",
trControl = cvCtrl
)
## remember getTrainPerf?
getTrainPerf(mod1)
mod1
set.seed(1)
mod2 <- train(x = as.matrix(df.train[, -1]),
y = as.factor(df.train$rich),
method = "svmLinear2",
trControl = cvCtrl
)
getTrainPerf(mod2)
set.seed(1)
mod3 <- train(x = as.matrix(df.train[, -1]),
y = as.factor(df.train$rich),
method = "knn",
trControl = cvCtrl
)
getTrainPerf(mod3)
mod3
set.seed(1)
mod4 <- train(x = as.matrix(df.train[, -1]),
y = as.factor(df.train$rich),
method = "rf",
trControl = cvCtrl
)
getTrainPerf(mod4) # not great!
set.seed(1)
mod5 <- train(x = as.matrix(df.train[, -1]),
y = as.factor(df.train$rich),
method = "nnet",
trControl = cvCtrl
)
mod5
getTrainPerf(mod5)
set.seed(1)
mod6 <- train(x = as.matrix(df.train[, -1]),
y = as.factor(df.train$rich),
method = "bayesglm",
trControl = cvCtrl
)
getTrainPerf(mod6)
mod2$method
mod2$method
mod2.out <- predict(mod2, newdata = df.test[ -1])
confusionMatrix(data = mod2.out, reference = df.test$rich)
mod3$method
mod3.out <- predict(mod3, newdata = df.test[ -1])
confusionMatrix(data = mod3.out, reference = df.test$rich)
mod4$method
mod4.out <- predict(mod4, newdata = df.test[ -1])
confusionMatrix(data = mod4.out, reference = df.test$rich)
mod5$method
mod5.out <- predict(mod5, newdata = df.test[ -1])
confusionMatrix(data = mod5.out, reference = df.test$rich)
mod6$method
mod6.out <- predict(mod6, newdata = df.test[ -1])
confusionMatrix(data = mod6.out, reference = df.test$rich)
t <- getModelInfo()
m <- list()
for (i in names(t)){
if (t[[i]]$type != "Regression"){
m <- c(m, t[i])
}
}
names(m)[1:5]
names(m)
set.seed(123)
modDef <- train(x = as.matrix(df.train[, -1]),
y = as.factor(df.train$rich),
method = "rf",
trControl = cvCtrl
)
print(modDef)
getTrainPerf(modDef)
set.seed(123)
modNoGrid <- train(x = as.matrix(df.train[, -1]),
y = as.factor(df.train$rich),
method = "rf",
tuneLength = 10,
trControl = cvCtrl
)
print(modNoGrid)
ggplot(modNoGrid)
getTrainPerf(modNoGrid)
rfGrid <- expand.grid(mtry = seq(3, 21, by = 3))
set.seed(123)
modGrid <- train(x = as.matrix(df.train[, -1]),
y = as.factor(df.train$rich),
method = "rf",
tuneGrid = rfGrid,
trControl = cvCtrl
)
print(modGrid)
getTrainPerf(modGrid)
# try smaller values of mtry, but sampling more closely?
rfGrid2 <- expand.grid(mtry = seq(3, 10, by = 1))
set.seed(123)
modGrid2 <- train(x = as.matrix(df.train[, -1]),
y = as.factor(df.train$rich),
method = "rf",
tuneGrid = rfGrid2,
trControl = cvCtrl
)
print(modGrid2)
getTrainPerf(modGrid2)
modDef$bestTune
modDef.out <- predict(modDef, newdata = df.test[ -1])
confusionMatrix(data = modDef.out, reference = df.test$rich)
modNoGrid$bestTune
modNoGrid.out <- predict(modNoGrid, newdata = df.test[ -1])
confusionMatrix(data = modNoGrid.out, reference = df.test$rich)
modGrid$bestTune
modGrid.out <- predict(modGrid, newdata = df.test[ -1])
confusionMatrix(data = modGrid.out, reference = df.test$rich)
modGrid2$bestTune
modGrid2.out <- predict(modGrid2, newdata = df.test[ -1])
confusionMatrix(data = modGrid2.out, reference = df.test$rich)
## parameter tuning seemed to help here because the defaults were inappropriate
## parameter tuning seemed to help here because the defaults were inappropriate
## for these data it takes time/experience to get used to tuning algorithms
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
################################################################################
